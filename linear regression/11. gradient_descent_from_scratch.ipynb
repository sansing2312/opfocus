{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d129e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sanju\\onedrive\\desktop\\ml\\ml specialization\\week1\\files (1)\\files\\home\\jovyan\\work\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a4bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_bias(X):\n",
    "    return np.c_[np.ones((X.shape[0], 1)),X]\n",
    "\n",
    "def standardize(X):\n",
    "    \"\"\"\n",
    "    Standardize features to zero mean and unit variance.\n",
    "    Returns transformed X, means, stds (to transform new data later).\n",
    "    \"\"\"\n",
    "    mu = X.mean(axis=0) \n",
    "    sigma = X.std(axis=0, ddof=0) \n",
    "    sigma[sigma==0] = 1.0\n",
    "    Xs = (X - mu) / sigma\n",
    "    return Xs, mu, sigma \n",
    "\n",
    "\n",
    "def compute_cost(Xb, y, theta, l2=0.0):\n",
    "    \"\"\"\n",
    "    Xb: design matrix with bias column [m x (n+1)]\n",
    "    y:  [m]\n",
    "    theta: [(n+1)]\n",
    "    l2: L2 regularization strength (lambda). Bias not regularized.\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    residuals = Xb @ theta - y\n",
    "    mse = (residuals @ residuals) / (2*m)\n",
    "    if l2 > 0:\n",
    "        # exclude bias from L2\n",
    "        mse += (l2 / (2*m)) * (theta[1:] @ theta[1:])\n",
    "    return mse\n",
    "\n",
    "\n",
    "def gradient_descent(X,y, alpha=0.1, iters=1000, l2=0.0, tol=None, verbose=False):\n",
    "     #feature scale \n",
    "\n",
    "     Xs,mu,sigma = standardize(X)\n",
    "\n",
    "     #add bias to column \n",
    "     Xb = add_bias(Xs) \n",
    "     m,n1=Xb.shape \n",
    "\n",
    "     #Init Params \n",
    "     rng = np.random.default_rng(0)\n",
    "     theta = rng.normal(0,0.01,size=n1)\n",
    "     history = [] \n",
    "\n",
    "     prev_cost = None \n",
    "     for t in range(iters): \n",
    "         #prediction and gradient \n",
    "         preds = Xb @ theta \n",
    "         error = preds - y \n",
    "         grad = (Xb.T @ error)/m \n",
    "         if l2 > 0:\n",
    "            reg = np.r_[0.0, l2 * theta[1:]] / m  # don't regularize bias\n",
    "            grad += reg\n",
    "        \n",
    "        #update \n",
    "         theta-=alpha*grad \n",
    "\n",
    "        #track cost \n",
    "         J=compute_cost(Xb, y, theta, l2=l2)\n",
    "         history.append(J)\n",
    "         if verbose and (t % max(1, iters//10) == 0):\n",
    "            print(f\"iter {t:5d}  cost {J:.6f}\")\n",
    "\n",
    "         if tol is not None and prev_cost is not None and abs(prev_cost - J) < tol:\n",
    "            if verbose:\n",
    "                print(f\"Converged at iter {t} (Î”J < tol).\")\n",
    "            break\n",
    "         prev_cost = J\n",
    "    \n",
    "    #pack scaler for future use\n",
    "     scaler = {\"mu\": mu, \"sigma\": sigma}\n",
    "     return theta, scaler, history   \n",
    "\n",
    "def predict(X, theta, scaler):\n",
    "    \"\"\"Predict on new data using learned theta and saved scaler.\"\"\"\n",
    "    Xs = (X - scaler[\"mu\"]) / scaler[\"sigma\"]\n",
    "    Xb = add_bias(Xs)\n",
    "    return Xb @ theta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1c27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cost: 141.2623590845302\n",
      "Theta (bias + weights): [572.5         65.72145678  24.35612313  10.48054746]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1500, 3, 10],\n",
    "    [1800, 4, 5],\n",
    "    [2400, 4, 20],\n",
    "    [3000, 5, 8],\n",
    "    [3500, 5, 12],\n",
    "    [2200, 3, 15],\n",
    "    [2600, 4, 7],\n",
    "    [2800, 4, 9],\n",
    "], dtype=float)\n",
    "\n",
    "y = np.array([400, 500, 600, 650, 700, 520, 590, 620], dtype=float)  # in $1,000s\n",
    "\n",
    "theta, scaler, history = gradient_descent(\n",
    "    X, y,\n",
    "    alpha=0.1,\n",
    "    iters=5000,\n",
    "    l2=0.0,     # try 0.1 to see L2 effect\n",
    "    tol=1e-9,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Final cost:\", history[-1])\n",
    "print(\"Theta (bias + weights):\", theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59fb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
